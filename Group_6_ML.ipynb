{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b29e218",
   "metadata": {},
   "source": [
    "![Kickstarter-Logo](Kickstarter-Logo.png)\n",
    "\n",
    "# 2487 MACHINE LEARNING - FINAL PROJECT\n",
    "#### GROUP 6: \n",
    "- Maria Baglieri Occhipinti (49638)\n",
    "- Moritz Constantin Güttersberger (48845)\n",
    "- Moritz Lilleholt Häckel (49558)\n",
    "- Eugenia Saggioro (50958)\n",
    "- Dominik Trut (46274)\n",
    "\n",
    "### **TABLE OF CONTENTS**\n",
    "\n",
    "[**1. FROM BUSINESS PROBLEM TO MACHINE LEARNING**](#FROM-BUSINESS-PROBLEM-TO-MACHINE-LEARNING)\n",
    "\n",
    "   [1.1 Business Understanding](#Business-Understanding)\n",
    "\n",
    "   [1.2 Problem Definition](#Problem-Definition)\n",
    "\n",
    "[**2. DATA UNDERSTANDING**](#DATA-UNDERSTANDING)\n",
    "\n",
    "[2.1 Loading Data](#Loading-Data)\n",
    "\n",
    "[2.2 IDA](#Initial-Data-Analysis)\n",
    "   - [Structure and Quality of Data](#Structure-and-Quality-of-Data)\n",
    "   - [Data Cleaning](#Data-Cleaning)\n",
    "   - [Feature Engineering](#Feature-Engineering)\n",
    "   - [Descriptive Statistics](Descriptive-Statistics)\n",
    "\n",
    "[2.3 EDA](#Exploratory-Data-Analysis)\n",
    "   - [Data Preparation](#Data-Preparation)\n",
    "   - [Data Visualization](#Data-Visualization)\n",
    "   - [Preprocessing and Feature Selection](#Preprocessing-and-Feature-Selection)\n",
    "\n",
    "[**4. MODELING**](#MODELING)\n",
    "\n",
    "[**5. EVALUATION**](#EVALUATION)\n",
    "\n",
    "[**6. CONCLUSIONS**](#CONCLUSIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39da6b6c",
   "metadata": {},
   "source": [
    "## FROM BUSINESS PROBLEM TO MACHINE LEARNING\n",
    "\n",
    "#### Business Understanding\n",
    "Kickstarter is a crowdfunding platform that allows people to support creative projects. Film, gaming, and music, as well as art, design, and technology projects, are all covered.\n",
    "\n",
    "The dataset at hand was crawled from the platform and contains detailed information about all current and historic projects on Kickstarter, as well as their status (successful, failed, canceled, live, suspended). \n",
    "\n",
    "Every project creator establishes a financing target (funding goal) and a deadline for their project. People can donate money to help make the concept a reality if they like it. Funding on Kickstarter is *“all-or-nothing”*. If the project meets its funding goal, all backers' credit cards will be charged after the deadline passes and Kickstarter deducts a 5% fee from pledged amount. On the other hand, if the projects fall short of its funding goal, no one is charged. \n",
    "\n",
    "Project creators retain complete ownership of their work. After a project is deemed successful, Kickstarter cannot be used to seek loans or to give financial returns or equity. Backers can support projects to help them come to life, not to profit monetarily. \n",
    "\n",
    "As stated from the platform’s website, while 10% of projects finished having never received a single pledge, 78% of projects that raised more than 20% of their goal were successfully funded. Therefore Kickstarter has a great potential to bring ideas to fruition. At the same time, Kickstarter's project have few risky characteristics for backers who want to invest in successful projects: \n",
    "- Items are frequently new and not evaluated in a mature market before.\n",
    "- Creators may be unskilled and lack the necessary abilities to develop and launch products.\n",
    "\n",
    "#### Problem Definition\n",
    "\n",
    "During the course of this project, we will take the perspective of project creators to assist them in optimizing their proposal, as well as backers' position to help them choosing where to invest their money. From the point of view of investors, the risk of losing one's capital as a result of a failed investment is high. Therefore, it would be convenient to put money into initiatives that have the best chance of succeeding. \n",
    "\n",
    "For a project’s success or failure on crowdfunding platforms, it’s important to consider the influence of all the factors characterizing that project. Some of these factors can be measured or classified, allowing for the development of a model to forecast whether a project will succeed or fail. \n",
    "\n",
    "Some projects are more successful than others and our intuition is that this does not always depend on the key idea. Some projects might fail because they don’t hit the target (backers) due to wrong descriptions, uncommon topic, too high funding goal or simply the project doesn’t seem trustworthy\n",
    "\n",
    "The goal of this project is to analyze Kickstarter projects’ data and build a useful model for project creators to understand which features attract backers the most or which projects are most likely to collect a higher amount. We will try to find the main patterns and the odds of a project’s success. Thanks to this model, decision makers (project creators) will gain useful insights before publishing their project on the platform.\n",
    "\n",
    "In order to achieve the goal explained above, we will use a dataset crawled from Kickstarter, which contains detailed information about all current and historic projects on Kickstarter, as well as their status (successful, failed, canceled, live, suspended). The dataset contains all the projects hosted between 2009 and 18 October 2018.\n",
    "\n",
    "Given the **big amount** of original data available (205696 projects with more than 37 variables), and the reasons explained below, it is reasonable to involve automation to solve this problem. \n",
    "- There is no existing formula to answer the main question.The features of each project set on the platform contribute in different ways to its success and this cannot be translated into simple rules.\n",
    "- Analyzing the probability of success and which are the main drivers of the end result, project by project, would **not** be **feasible**. \n",
    "- Some columns like the description of the project (blurb) contain **unstructured text** which needs to be analyzed in depth with Natural language Processing. \n",
    "\n",
    "All in all, there is a big potential for data to be **represented in a meaningful way**, with both numbers and categorical values (e.g. state, status, location). In the next sections, we will explain these reasoning better.\n",
    "\n",
    "## DATA UNDERSTANDING\n",
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "417cdc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import seaborn as sns; sns.set()\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "import re\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import wordnet \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import set_config \n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score, precision_recall_fscore_support, accuracy_score, auc, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import validation_curve\n",
    "import itertools\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pyLDAvis.sklearn\n",
    "\n",
    "\n",
    "from sklearn import set_config \n",
    "import time\n",
    "import xgboost as xgb\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d3657fe9-57bb-45bb-845e-1afbf05961fa",
   "metadata": {},
   "source": [
    "# The following need to be rerun only if you don't have the packages\n",
    "!conda install nltk --yes\n",
    "! conda install -c conda-forge spacy --yes\n",
    "! python -m spacy download en_core_web_sm\n",
    "! pip install wordcloud\n",
    "! conda install -c anaconda gensim --yes\n",
    "! conda install -c conda-forge wordcloud --yes\n",
    "\n",
    ">>> nltk.download('wordnet')\n",
    "! pip install pyldavis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82304077-c010-44bf-9e56-d087029bf3f4",
   "metadata": {},
   "source": [
    "\n",
    "Import the available datasets and merge all the csv files to have all the data together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbf321ad-763b-4435-b06e-fb9e0505ea31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "files = [file for file in os.listdir('Kickstarter_Dataset')]\n",
    "\n",
    "all_df = pd.DataFrame()\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv('./Kickstarter_Dataset/'+file)\n",
    "    all_df = pd.concat([all_df, df])\n",
    "    \n",
    "all_df.to_csv(\"Kickstarter_Complete.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af440e5f-24f3-4d75-8dda-de3b4bcd8580",
   "metadata": {},
   "source": [
    "Import the complete dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "295e8a06-a867-4dcd-b966-cefd09be5e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backers_count</th>\n",
       "      <th>blurb</th>\n",
       "      <th>category</th>\n",
       "      <th>converted_pledged_amount</th>\n",
       "      <th>country</th>\n",
       "      <th>created_at</th>\n",
       "      <th>creator</th>\n",
       "      <th>currency</th>\n",
       "      <th>currency_symbol</th>\n",
       "      <th>currency_trailing_code</th>\n",
       "      <th>...</th>\n",
       "      <th>slug</th>\n",
       "      <th>source_url</th>\n",
       "      <th>spotlight</th>\n",
       "      <th>staff_pick</th>\n",
       "      <th>state</th>\n",
       "      <th>state_changed_at</th>\n",
       "      <th>static_usd_rate</th>\n",
       "      <th>urls</th>\n",
       "      <th>usd_pledged</th>\n",
       "      <th>usd_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>210</td>\n",
       "      <td>Believing Heart Tarot is a one of a kind addit...</td>\n",
       "      <td>{\"id\":21,\"name\":\"Digital Art\",\"slug\":\"art/digi...</td>\n",
       "      <td>14166</td>\n",
       "      <td>US</td>\n",
       "      <td>1513372142</td>\n",
       "      <td>{\"id\":1647802423,\"name\":\"Catstealers-Zines\",\"s...</td>\n",
       "      <td>USD</td>\n",
       "      <td>$</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>believing-heart-tarot-deck</td>\n",
       "      <td>https://www.kickstarter.com/discover/categorie...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>successful</td>\n",
       "      <td>1522555142</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
       "      <td>14166.00</td>\n",
       "      <td>international</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Be a part of Street Art Magic and have a hand ...</td>\n",
       "      <td>{\"id\":53,\"name\":\"Public Art\",\"slug\":\"art/publi...</td>\n",
       "      <td>42</td>\n",
       "      <td>US</td>\n",
       "      <td>1390444485</td>\n",
       "      <td>{\"id\":1960090658,\"name\":\"Inman E. Goodman III\"...</td>\n",
       "      <td>USD</td>\n",
       "      <td>$</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>zone-7-street-arts-initiative</td>\n",
       "      <td>https://www.kickstarter.com/discover/categorie...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>failed</td>\n",
       "      <td>1392323039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
       "      <td>42.00</td>\n",
       "      <td>international</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>My writing changed after my daughter was kille...</td>\n",
       "      <td>{\"id\":359,\"name\":\"Print\",\"slug\":\"journalism/pr...</td>\n",
       "      <td>1127</td>\n",
       "      <td>US</td>\n",
       "      <td>1404688773</td>\n",
       "      <td>{\"id\":2049496016,\"name\":\"Diane Neas\",\"is_regis...</td>\n",
       "      <td>USD</td>\n",
       "      <td>$</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>loving-becca-journey-of-child-loss</td>\n",
       "      <td>https://www.kickstarter.com/discover/categorie...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>successful</td>\n",
       "      <td>1407702831</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
       "      <td>1127.00</td>\n",
       "      <td>international</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The Sweet Botanist's natural syrups are made s...</td>\n",
       "      <td>{\"id\":307,\"name\":\"Drinks\",\"slug\":\"food/drinks\"...</td>\n",
       "      <td>105</td>\n",
       "      <td>US</td>\n",
       "      <td>1464156479</td>\n",
       "      <td>{\"id\":1723204437,\"name\":\"Amber M.\",\"is_registe...</td>\n",
       "      <td>USD</td>\n",
       "      <td>$</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>the-sweet-botanist-syrup-co</td>\n",
       "      <td>https://www.kickstarter.com/discover/categorie...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>failed</td>\n",
       "      <td>1466802580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
       "      <td>105.00</td>\n",
       "      <td>international</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>800</td>\n",
       "      <td>The digital restoration of the classic 1968 Ro...</td>\n",
       "      <td>{\"id\":30,\"name\":\"Documentary\",\"slug\":\"film &amp; v...</td>\n",
       "      <td>28720</td>\n",
       "      <td>US</td>\n",
       "      <td>1331149074</td>\n",
       "      <td>{\"id\":1765735821,\"name\":\"Fred Padula\",\"is_regi...</td>\n",
       "      <td>USD</td>\n",
       "      <td>$</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>el-capitan-film-restoration</td>\n",
       "      <td>https://www.kickstarter.com/discover/categorie...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>successful</td>\n",
       "      <td>1351739753</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
       "      <td>28720.42</td>\n",
       "      <td>international</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   backers_count                                              blurb  \\\n",
       "0            210  Believing Heart Tarot is a one of a kind addit...   \n",
       "1              3  Be a part of Street Art Magic and have a hand ...   \n",
       "2             31  My writing changed after my daughter was kille...   \n",
       "3              4  The Sweet Botanist's natural syrups are made s...   \n",
       "4            800  The digital restoration of the classic 1968 Ro...   \n",
       "\n",
       "                                            category  \\\n",
       "0  {\"id\":21,\"name\":\"Digital Art\",\"slug\":\"art/digi...   \n",
       "1  {\"id\":53,\"name\":\"Public Art\",\"slug\":\"art/publi...   \n",
       "2  {\"id\":359,\"name\":\"Print\",\"slug\":\"journalism/pr...   \n",
       "3  {\"id\":307,\"name\":\"Drinks\",\"slug\":\"food/drinks\"...   \n",
       "4  {\"id\":30,\"name\":\"Documentary\",\"slug\":\"film & v...   \n",
       "\n",
       "   converted_pledged_amount country  created_at  \\\n",
       "0                     14166      US  1513372142   \n",
       "1                        42      US  1390444485   \n",
       "2                      1127      US  1404688773   \n",
       "3                       105      US  1464156479   \n",
       "4                     28720      US  1331149074   \n",
       "\n",
       "                                             creator currency currency_symbol  \\\n",
       "0  {\"id\":1647802423,\"name\":\"Catstealers-Zines\",\"s...      USD               $   \n",
       "1  {\"id\":1960090658,\"name\":\"Inman E. Goodman III\"...      USD               $   \n",
       "2  {\"id\":2049496016,\"name\":\"Diane Neas\",\"is_regis...      USD               $   \n",
       "3  {\"id\":1723204437,\"name\":\"Amber M.\",\"is_registe...      USD               $   \n",
       "4  {\"id\":1765735821,\"name\":\"Fred Padula\",\"is_regi...      USD               $   \n",
       "\n",
       "   currency_trailing_code  ...                                slug  \\\n",
       "0                    True  ...          believing-heart-tarot-deck   \n",
       "1                    True  ...       zone-7-street-arts-initiative   \n",
       "2                    True  ...  loving-becca-journey-of-child-loss   \n",
       "3                    True  ...         the-sweet-botanist-syrup-co   \n",
       "4                    True  ...         el-capitan-film-restoration   \n",
       "\n",
       "                                          source_url  spotlight staff_pick  \\\n",
       "0  https://www.kickstarter.com/discover/categorie...       True      False   \n",
       "1  https://www.kickstarter.com/discover/categorie...      False      False   \n",
       "2  https://www.kickstarter.com/discover/categorie...       True      False   \n",
       "3  https://www.kickstarter.com/discover/categorie...      False      False   \n",
       "4  https://www.kickstarter.com/discover/categorie...       True      False   \n",
       "\n",
       "        state  state_changed_at  static_usd_rate  \\\n",
       "0  successful        1522555142              1.0   \n",
       "1      failed        1392323039              1.0   \n",
       "2  successful        1407702831              1.0   \n",
       "3      failed        1466802580              1.0   \n",
       "4  successful        1351739753              1.0   \n",
       "\n",
       "                                                urls  usd_pledged  \\\n",
       "0  {\"web\":{\"project\":\"https://www.kickstarter.com...     14166.00   \n",
       "1  {\"web\":{\"project\":\"https://www.kickstarter.com...        42.00   \n",
       "2  {\"web\":{\"project\":\"https://www.kickstarter.com...      1127.00   \n",
       "3  {\"web\":{\"project\":\"https://www.kickstarter.com...       105.00   \n",
       "4  {\"web\":{\"project\":\"https://www.kickstarter.com...     28720.42   \n",
       "\n",
       "        usd_type  \n",
       "0  international  \n",
       "1  international  \n",
       "2  international  \n",
       "3  international  \n",
       "4  international  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Kickstarter_Complete.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02d3be97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "backers_count                 int64\n",
       "blurb                        object\n",
       "category                     object\n",
       "converted_pledged_amount      int64\n",
       "country                      object\n",
       "created_at                    int64\n",
       "creator                      object\n",
       "currency                     object\n",
       "currency_symbol              object\n",
       "currency_trailing_code         bool\n",
       "current_currency             object\n",
       "deadline                      int64\n",
       "disable_communication          bool\n",
       "friends                      object\n",
       "fx_rate                     float64\n",
       "goal                        float64\n",
       "id                            int64\n",
       "is_backing                   object\n",
       "is_starrable                   bool\n",
       "is_starred                   object\n",
       "launched_at                   int64\n",
       "location                     object\n",
       "name                         object\n",
       "permissions                  object\n",
       "photo                        object\n",
       "pledged                     float64\n",
       "profile                      object\n",
       "slug                         object\n",
       "source_url                   object\n",
       "spotlight                      bool\n",
       "staff_pick                     bool\n",
       "state                        object\n",
       "state_changed_at              int64\n",
       "static_usd_rate             float64\n",
       "urls                         object\n",
       "usd_pledged                 float64\n",
       "usd_type                     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea2aa231-a841-4397-865b-dc97ef644649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 205696 entries, 0 to 205695\n",
      "Data columns (total 37 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   backers_count             205696 non-null  int64  \n",
      " 1   blurb                     205686 non-null  object \n",
      " 2   category                  205696 non-null  object \n",
      " 3   converted_pledged_amount  205696 non-null  int64  \n",
      " 4   country                   205696 non-null  object \n",
      " 5   created_at                205696 non-null  int64  \n",
      " 6   creator                   205696 non-null  object \n",
      " 7   currency                  205696 non-null  object \n",
      " 8   currency_symbol           205696 non-null  object \n",
      " 9   currency_trailing_code    205696 non-null  bool   \n",
      " 10  current_currency          205696 non-null  object \n",
      " 11  deadline                  205696 non-null  int64  \n",
      " 12  disable_communication     205696 non-null  bool   \n",
      " 13  friends                   276 non-null     object \n",
      " 14  fx_rate                   205696 non-null  float64\n",
      " 15  goal                      205696 non-null  float64\n",
      " 16  id                        205696 non-null  int64  \n",
      " 17  is_backing                276 non-null     object \n",
      " 18  is_starrable              205696 non-null  bool   \n",
      " 19  is_starred                276 non-null     object \n",
      " 20  launched_at               205696 non-null  int64  \n",
      " 21  location                  204404 non-null  object \n",
      " 22  name                      205695 non-null  object \n",
      " 23  permissions               276 non-null     object \n",
      " 24  photo                     205696 non-null  object \n",
      " 25  pledged                   205696 non-null  float64\n",
      " 26  profile                   205696 non-null  object \n",
      " 27  slug                      205696 non-null  object \n",
      " 28  source_url                205696 non-null  object \n",
      " 29  spotlight                 205696 non-null  bool   \n",
      " 30  staff_pick                205696 non-null  bool   \n",
      " 31  state                     205696 non-null  object \n",
      " 32  state_changed_at          205696 non-null  int64  \n",
      " 33  static_usd_rate           205696 non-null  float64\n",
      " 34  urls                      205696 non-null  object \n",
      " 35  usd_pledged               205696 non-null  float64\n",
      " 36  usd_type                  203968 non-null  object \n",
      "dtypes: bool(5), float64(5), int64(7), object(20)\n",
      "memory usage: 51.2+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc5bfdd",
   "metadata": {},
   "source": [
    "#### Structure and Quality of the Data\n",
    "\n",
    "The amount of data available is enough to build a machine learning model. We have information regarding:\n",
    "- The type of the project (category, subcategory, brief description, its profile)\n",
    "- The creator\n",
    "- The start date, the duration of the crowdfunding, and the date when the status of the project was changed \n",
    "- The funding goal, the pledged amount, the original currency, the exchange rate and the converted pledged amount. \n",
    "- The number of backers achieved. \n",
    "For more information regarding the variables available, please see the below sections.\n",
    "\n",
    "The **quality** and the **quantity** of data are fundamental to building an efficient model. The data available is complete and consistent across the datasets. There are some variables with almost all empty cells (friends, is_starred, etc.) and some others with an invalid format (category, creator, location, etc.) that must be modified or dropped. \n",
    "\n",
    "Around 55% of the projects available are successful, ~ 36% are labeled as failed and the rest is live/canceled/suspended. This means we have little information regarding the canceled projects. Nevertheless, we have a big and balanced amount of successful and failed projects. \n",
    "\n",
    "12% of the projects are current ones, while around 88% are past projects. This difference is valuable since we will work on past projects to build an efficient model and apply it to current projects. \n",
    "\n",
    "Projects are split into 15 categories and 159 subcategories. As we can see on the right, Music, Film & Video and Technology are the categories with more projects while Dance is the category with only 3 subcategories and 3156 projects (less than 2% of the entire dataset).\n",
    "\n",
    "All in all, we can state the quality of data is good enough to work on it and create a model. \n",
    "\n",
    "Data available presents **regular patterns** between the independent variables (inputs) and the final result (success/failure, pledged amount)\n",
    "These patterns are necessary for the model to learn from them and to extract a valid output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479e5086-27ef-4eff-a972-9f2ebd7c4dbc",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "#### Columns to delete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeb7186-bbd1-4d5a-873c-d9d6067356aa",
   "metadata": {},
   "source": [
    "We decided to preliminary delete the following columns as they are not useful for our analysis: \n",
    "- currency_symbol: the symbol of the original currency the project goal was denominated in.\n",
    "- currency_trailing_code: the code of the original currency the project goal was denominated in.\n",
    "- id: id number of the project.\n",
    "- photo: contains a link and information to the project's image.\n",
    "- permissions: just 276 values. \n",
    "- friends: just 274 values.\n",
    "- source_url: url for the project's category.\n",
    "- is_backing: just 276 values.\n",
    "- is_starred: just 276 values.\n",
    "- usd_type: international or domestic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd373d89-59b3-423b-913f-66d694beb481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "del df['currency_symbol']\n",
    "del df['currency_trailing_code']\n",
    "del df['id']\n",
    "del df['photo']\n",
    "del df['permissions']\n",
    "del df['friends']\n",
    "del df['source_url']\n",
    "del df['is_backing']\n",
    "del df['is_starred']\n",
    "del df['usd_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a6acdf-937d-48e3-83b1-745dda3cc557",
   "metadata": {},
   "source": [
    "#### Rename backers_count into nr_backers.\n",
    "backers_count shows the number of backers for that project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c087ab5-65c7-4a35-8ece-c7f6063abeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "df=df.rename(columns={\"backers_count\":\"nr_backers\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f6ca2d-4659-4023-8e4f-860ee1b74a4e",
   "metadata": {},
   "source": [
    "#### Create 3 new columns from the category column: category, subcategory and category_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc68f340-18c4-4add-afd5-c90d5918f9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "df=df.rename(columns={\"category\":\"Category\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c98fd41-3c52-4de2-ac15-ade398163d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "df['category'] = df['Category'].apply(lambda x: x.split('\"slug\":\"')[1].split('/')[0])\n",
    "df['category'] = df['category'].apply(lambda x: x.split('\"')[0])\n",
    "df['subcategory'] = df['Category'].apply(lambda x: x.split('\"name\":\"')[1].split('\"')[0])\n",
    "df['subcategory_id'] = df['Category'].apply(lambda x: x.split('\"id\":')[1].split(',')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9034b2af-d08a-47ac-a7c2-d76cb46a8003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "del df['Category']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e69e0c4-6dae-4b3d-99f8-fb6c066a1e7d",
   "metadata": {},
   "source": [
    "#### Modify the date time columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e985b17-300c-4909-b11e-6f49c731bf5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "df['created_at'] = pd.to_datetime(df['created_at'], unit=\"s\").dt.date\n",
    "df['state_changed_at'] = pd.to_datetime(df['state_changed_at'], unit=\"s\").dt.date\n",
    "df['deadline'] = pd.to_datetime(df['deadline'], unit=\"s\").dt.date\n",
    "df['launched_at'] = pd.to_datetime(df['launched_at'], unit=\"s\").dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b544f601-bda3-4d35-b08b-53a5773f6f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nr_backers</th>\n",
       "      <th>blurb</th>\n",
       "      <th>converted_pledged_amount</th>\n",
       "      <th>country</th>\n",
       "      <th>created_at</th>\n",
       "      <th>creator</th>\n",
       "      <th>currency</th>\n",
       "      <th>current_currency</th>\n",
       "      <th>deadline</th>\n",
       "      <th>disable_communication</th>\n",
       "      <th>...</th>\n",
       "      <th>spotlight</th>\n",
       "      <th>staff_pick</th>\n",
       "      <th>state</th>\n",
       "      <th>state_changed_at</th>\n",
       "      <th>static_usd_rate</th>\n",
       "      <th>urls</th>\n",
       "      <th>usd_pledged</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>subcategory_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>210</td>\n",
       "      <td>Believing Heart Tarot is a one of a kind addit...</td>\n",
       "      <td>14166</td>\n",
       "      <td>US</td>\n",
       "      <td>2017-12-15</td>\n",
       "      <td>{\"id\":1647802423,\"name\":\"Catstealers-Zines\",\"s...</td>\n",
       "      <td>USD</td>\n",
       "      <td>USD</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>successful</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
       "      <td>14166.00</td>\n",
       "      <td>art</td>\n",
       "      <td>Digital Art</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Be a part of Street Art Magic and have a hand ...</td>\n",
       "      <td>42</td>\n",
       "      <td>US</td>\n",
       "      <td>2014-01-23</td>\n",
       "      <td>{\"id\":1960090658,\"name\":\"Inman E. Goodman III\"...</td>\n",
       "      <td>USD</td>\n",
       "      <td>USD</td>\n",
       "      <td>2014-02-13</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>failed</td>\n",
       "      <td>2014-02-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
       "      <td>42.00</td>\n",
       "      <td>art</td>\n",
       "      <td>Public Art</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>My writing changed after my daughter was kille...</td>\n",
       "      <td>1127</td>\n",
       "      <td>US</td>\n",
       "      <td>2014-07-06</td>\n",
       "      <td>{\"id\":2049496016,\"name\":\"Diane Neas\",\"is_regis...</td>\n",
       "      <td>USD</td>\n",
       "      <td>USD</td>\n",
       "      <td>2014-08-10</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>successful</td>\n",
       "      <td>2014-08-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
       "      <td>1127.00</td>\n",
       "      <td>journalism</td>\n",
       "      <td>Print</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The Sweet Botanist's natural syrups are made s...</td>\n",
       "      <td>105</td>\n",
       "      <td>US</td>\n",
       "      <td>2016-05-25</td>\n",
       "      <td>{\"id\":1723204437,\"name\":\"Amber M.\",\"is_registe...</td>\n",
       "      <td>USD</td>\n",
       "      <td>USD</td>\n",
       "      <td>2016-06-24</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>failed</td>\n",
       "      <td>2016-06-24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
       "      <td>105.00</td>\n",
       "      <td>food</td>\n",
       "      <td>Drinks</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>800</td>\n",
       "      <td>The digital restoration of the classic 1968 Ro...</td>\n",
       "      <td>28720</td>\n",
       "      <td>US</td>\n",
       "      <td>2012-03-07</td>\n",
       "      <td>{\"id\":1765735821,\"name\":\"Fred Padula\",\"is_regi...</td>\n",
       "      <td>USD</td>\n",
       "      <td>USD</td>\n",
       "      <td>2012-11-01</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>successful</td>\n",
       "      <td>2012-11-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"web\":{\"project\":\"https://www.kickstarter.com...</td>\n",
       "      <td>28720.42</td>\n",
       "      <td>film &amp; video</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   nr_backers                                              blurb  \\\n",
       "0         210  Believing Heart Tarot is a one of a kind addit...   \n",
       "1           3  Be a part of Street Art Magic and have a hand ...   \n",
       "2          31  My writing changed after my daughter was kille...   \n",
       "3           4  The Sweet Botanist's natural syrups are made s...   \n",
       "4         800  The digital restoration of the classic 1968 Ro...   \n",
       "\n",
       "   converted_pledged_amount country  created_at  \\\n",
       "0                     14166      US  2017-12-15   \n",
       "1                        42      US  2014-01-23   \n",
       "2                      1127      US  2014-07-06   \n",
       "3                       105      US  2016-05-25   \n",
       "4                     28720      US  2012-03-07   \n",
       "\n",
       "                                             creator currency  \\\n",
       "0  {\"id\":1647802423,\"name\":\"Catstealers-Zines\",\"s...      USD   \n",
       "1  {\"id\":1960090658,\"name\":\"Inman E. Goodman III\"...      USD   \n",
       "2  {\"id\":2049496016,\"name\":\"Diane Neas\",\"is_regis...      USD   \n",
       "3  {\"id\":1723204437,\"name\":\"Amber M.\",\"is_registe...      USD   \n",
       "4  {\"id\":1765735821,\"name\":\"Fred Padula\",\"is_regi...      USD   \n",
       "\n",
       "  current_currency    deadline  disable_communication  ...  spotlight  \\\n",
       "0              USD  2018-04-01                  False  ...       True   \n",
       "1              USD  2014-02-13                  False  ...      False   \n",
       "2              USD  2014-08-10                  False  ...       True   \n",
       "3              USD  2016-06-24                  False  ...      False   \n",
       "4              USD  2012-11-01                  False  ...       True   \n",
       "\n",
       "   staff_pick       state state_changed_at static_usd_rate  \\\n",
       "0       False  successful       2018-04-01             1.0   \n",
       "1       False      failed       2014-02-13             1.0   \n",
       "2       False  successful       2014-08-10             1.0   \n",
       "3       False      failed       2016-06-24             1.0   \n",
       "4       False  successful       2012-11-01             1.0   \n",
       "\n",
       "                                                urls  usd_pledged  \\\n",
       "0  {\"web\":{\"project\":\"https://www.kickstarter.com...     14166.00   \n",
       "1  {\"web\":{\"project\":\"https://www.kickstarter.com...        42.00   \n",
       "2  {\"web\":{\"project\":\"https://www.kickstarter.com...      1127.00   \n",
       "3  {\"web\":{\"project\":\"https://www.kickstarter.com...       105.00   \n",
       "4  {\"web\":{\"project\":\"https://www.kickstarter.com...     28720.42   \n",
       "\n",
       "       category  subcategory  subcategory_id  \n",
       "0           art  Digital Art              21  \n",
       "1           art   Public Art              53  \n",
       "2    journalism        Print             359  \n",
       "3          food       Drinks             307  \n",
       "4  film & video  Documentary              30  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa354f6-7e0b-42cf-8151-99a76da5ba63",
   "metadata": {},
   "source": [
    "The timeframe in which this projects have been created is:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf54fe8-232f-4b14-a27e-6630ac2b23b5",
   "metadata": {},
   "source": [
    "#### Create 4 new columns from the creator one: creator_id, creator_name, is_registered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d976407-2814-4ace-a610-4ade6fe12042",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "df['creator_id'] = df['creator'].apply(lambda x: x.split('\"id\":')[1].split(',')[0])\n",
    "df['creator_name'] = df['creator'].apply(lambda x: x.split('\"name\":\"')[1].split('\"')[0])\n",
    "df['is_creator_registered'] = df['creator'].apply(lambda x: x.split('\"is_registered\":')[1].split(',')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e63d60e1-c393-409c-98d6-1db56af60ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "del df['creator']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08572bc-d9a9-4c06-8db1-b34d9f575e04",
   "metadata": {},
   "source": [
    "#### Create 2 new columns from the location one: city and state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d02fa66d-5b2f-4714-bfef-7b3a19308bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "df['nation'] = df['location'].astype(str).apply(lambda x: x.split('\"state\":\"')[1].split('\"')[0] if len(x.split('\"state\":\"'))>1 else x.split('-')[0])\n",
    "df['city'] = df['location'].astype(str).apply(lambda x: x.split('\"name\":\"')[1].split('\"')[0] if len(x.split('\"name\":\"'))>1 else x.split('-')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd51846d-cdce-4d56-824d-1da8ae9bb043",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "del df['location']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc7c40c-251a-49f9-ab13-407af2a6731c",
   "metadata": {},
   "source": [
    "#### Create 2 columns from the profile one: project_id and project_status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "784661e6-4374-4a5b-b1c4-fc92904d3a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "df['project_id'] = df['profile'].apply(lambda x: x.split('\"id\":')[1].split(',')[0])\n",
    "df['project_status'] = df['profile'].apply(lambda x: x.split('\"state\":\"')[1].split('\"')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b58c53e1-b723-4ba0-b972-358472dc4d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "del df['profile']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e28ad9-a5ca-4325-a61b-346a7108a2cd",
   "metadata": {},
   "source": [
    "#### Modify the urls column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "216ca43f-e4fc-4b6e-9a8e-d92a9b878b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "df['url'] = df['urls'].apply(lambda x: x.split('\"project\":\"')[1].split('\"')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0831d8a1-c490-4506-81d6-bedbe0d5c3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "del df['urls']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd544308-5efb-4425-a90a-91a61ece7d40",
   "metadata": {},
   "source": [
    "#### Converting the goal in USD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c4c9a4b-64e0-4b3f-b077-feabb43211d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "df['usd_goal'] = round(df['goal'] * df['static_usd_rate'],2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc121ac-24eb-4258-98f4-203eac6123b4",
   "metadata": {},
   "source": [
    "Given that we have a new column with the goal of all projects in USD we can drop these two columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62e6dca3-1fff-4f27-be30-f45ae9b31478",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "del df['goal']\n",
    "del df['static_usd_rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c55c3f-3af5-4727-ae6a-0afcbfa1d9a4",
   "metadata": {},
   "source": [
    "#### Dropping duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceafbfe-abe6-4ed0-b4fc-ee3e0055a9a5",
   "metadata": {},
   "source": [
    "Check the number of projects that are listed more than one and drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f63032ee-797f-46d6-81a9-89c32496f2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of duplicates is 18622 over 205696 projects.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The number of duplicates is {len(df[df.duplicated(subset='project_id')])} over {len(df)} projects.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10913e51-d021-498a-b9b3-de83aa4dd5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad1720d-22a6-4f34-b2b4-a2a184768221",
   "metadata": {},
   "source": [
    "#### Ordering the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f2c68e1-34b4-4b1a-a42a-47a08016a484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['creation_to_launch_days', 'deadline_month', 'launch_day', 'campaign_days', 'launch_month', 'blurb_len', 'deadline_day', 'pledge_per_backer', 'name_len'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-0ab229dd651d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m df = df[['project_id', 'state', 'name','name_len', 'slug', 'blurb','blurb_len', 'url', 'category', 'subcategory','subcategory_id', \n\u001b[0m\u001b[1;32m      2\u001b[0m          \u001b[0;34m'country'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'created_at'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'city'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m          \u001b[0;34m'launched_at'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'launch_day'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'launch_month'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'creation_to_launch_days'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'deadline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'deadline_day'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'deadline_month'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'campaign_days'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m          \u001b[0;34m'nr_backers'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'pledge_per_backer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'usd_goal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pledged'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'currency'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'usd_pledged'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'current_currency'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m          'fx_rate', 'project_status', 'state_changed_at', 'disable_communication', 'is_starrable', 'spotlight', 'staff_pick' ]]\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3028\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3029\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3030\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3032\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1314\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['creation_to_launch_days', 'deadline_month', 'launch_day', 'campaign_days', 'launch_month', 'blurb_len', 'deadline_day', 'pledge_per_backer', 'name_len'] not in index\""
     ]
    }
   ],
   "source": [
    "df = df[['project_id', 'state', 'name','name_len', 'slug', 'blurb','blurb_len', 'url', 'category', 'subcategory','subcategory_id', \n",
    "         'country', 'created_at', 'nation', 'city', \n",
    "         'launched_at','launch_day','launch_month','creation_to_launch_days','deadline','deadline_day','deadline_month','campaign_days', \n",
    "         'nr_backers','pledge_per_backer', 'usd_goal', 'pledged', 'currency', 'usd_pledged', 'current_currency', \n",
    "         'fx_rate', 'project_status', 'state_changed_at', 'disable_communication', 'is_starrable', 'spotlight', 'staff_pick' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd52391",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4c6a01-86cd-4619-a4c0-8780ca2fa149",
   "metadata": {},
   "source": [
    "#### Saving the new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc95b7be-c109-4d2f-b05c-e080862d1829",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Cleaned_Kickstarter.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6839f9b-1387-4efe-98c1-ac55e7dfad6d",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "Create new variables useful for the understanding of projects' characteristics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9778ff21-9082-4d3d-bb0d-4443510180a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#Name: Word length\n",
    "df['name_len'] = df['name'].str.split().str.len()\n",
    "df.name_len.fillna(0, inplace=True)\n",
    "\n",
    "#Blurb: Word length\n",
    "df['blurb_len'] = df['blurb'].str.split().str.len()\n",
    "df.blurb_len.fillna(0, inplace=True)\n",
    "\n",
    "#Slug: Word length\n",
    "df['slug_len'] = df['slug'].str.split(\"-\").str.len()\n",
    "df.slug_len.fillna(0, inplace=True)\n",
    "\n",
    "#Average pledge per backer\n",
    "df['pledge_per_backer'] = round(df['usd_pledged']/df['nr_backers'],2)\n",
    "\n",
    "#Time between creating and launching the project\n",
    "df['creation_to_launch_days'] = df['launched_at'] - df['created_at']\n",
    "df['creation_to_launch_days'] = df['creation_to_launch_days'].dt.round('d').dt.days\n",
    "\n",
    "#Length of the campaign\n",
    "df['campaign_days'] = df['deadline'] - df['launched_at']\n",
    "df['campaign_days'] = df['campaign_days'].dt.round('d').dt.days\n",
    "\n",
    "# Launch and deadline day of week\n",
    "df['launched_at'] = pd.to_datetime(df.launched_at, format='%Y-%m-%d')\n",
    "df['launch_day'] = df['launched_at'].dt.day_name()\n",
    "df['deadline'] = pd.to_datetime(df.deadline, format='%Y-%m-%d')\n",
    "df['deadline_day'] = df['deadline'].dt.day_name()\n",
    "\n",
    "# Launch and deadline month\n",
    "df['launch_month'] = df['launched_at'].dt.month_name()\n",
    "df['deadline_month'] = df['deadline'].dt.month_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111de351",
   "metadata": {},
   "source": [
    "#### Description of our final variables.\n",
    "\n",
    "- **project_id**: id of the project.\n",
    "- **state**: status of the project (successful, failed, canceled, live, suspended)\n",
    "- **name**: name of the project.\n",
    "- **name_len**: length of the name. \n",
    "- **slug**: keywords put by the creator about the project.\n",
    "- **slug_len**: length of slug\n",
    "- **blurb**: description of what’s the project about.\n",
    "- **blurb_len**: length of the blurb.\n",
    "- **url**: url of the project.\n",
    "- **category**: category of the project.\n",
    "- **subcategory**: subcategory of the project.\n",
    "- **subcategory_id**: id of the subcategory of the project.\n",
    "- **creator_id**: id of the creator of the project.\n",
    "- **creator_name**: name of the creator of the project.\n",
    "- **is_creator_registered**: boolean variable\n",
    "- **country**: country where the project has originated.\n",
    "- **nation**: nation where the project has originated.\n",
    "- **city**: city where the project has originated.\n",
    "- **created_at**: when the project has been created - yyyy/mm/dd.\n",
    "- **launched_at**: launch date of the project - yyyy/mm/dd.\n",
    "- **launch_day**: day of the week in which the project has been launched. \n",
    "- **launch_month**: month in which the project has been launched.\n",
    "- **creation_to_launch_days**: number of days between the creation and the launch of the project.\n",
    "- **deadline**: deadline of the project - yyyy/mm/dd.\n",
    "- **deadline_day**: day of the week in which the project has been closed. \n",
    "- **deadline_month**: month in which the project has been closed.\n",
    "- **campaign_days**: number of days between the launch and the deadline. \n",
    "- **nr_backers**: number of backers for the project.\n",
    "- **pledge_per_backer**: total amount of money pledged divided by the number of backers. \n",
    "- **usd_goal**: amount of money for reaching the goal in usd.\n",
    "- **pledged**: pledged amount in the initial currency.\n",
    "- **currency**: currency of the project.\n",
    "- **usd_pledged**: pledged amount multiplied for the static usd rate.             \n",
    "- **current_currency**: current currency of the project.\n",
    "- **fx_rate**: exchange rate.                                 \n",
    "- **project_status**: active or inactive          \n",
    "- **state_changed_at**: when the state of the project changed - yyyy/mm/dd.         \n",
    "- **disable_communication**: status about communication, id false for all campaigns that have ended.   \n",
    "- **is_starrable**: how successful Kickstarter believes the campaign will be.           \n",
    "- **spotlight**: after your project is successfully funded you will gain access to the Spotlight page tool which allows you to make a home for your project.   \n",
    "- **staff_pick**: feature that highlights promising projects on the site to give them a boost by helping them get exposure through email newsletter and highlighted spots around the site."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e132673",
   "metadata": {},
   "source": [
    "### Main Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c37af21-cb97-434d-a621-14afd234c647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The datasets dates range between 21 April 2009 and 18 October 2018.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "print(f\"The datasets dates range between {min(df.created_at).strftime('%d %B %Y')} and {max(df.created_at).strftime('%d %B %Y')}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c6052e",
   "metadata": {},
   "source": [
    "How many successful/failed/canceled projects?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a3ca555",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "successful    53.284702\n",
       "failed        39.392096\n",
       "canceled       4.513259\n",
       "live           2.483562\n",
       "suspended      0.326381\n",
       "Name: state, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['state'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894351d9",
   "metadata": {},
   "source": [
    "Statistics regarding categories and subcategories available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c77ebd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 15 categories\n",
      "There are 159 subcategories\n",
      "There are 22411 current projects and 166632 past ones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "nr_category = df['category'].nunique()\n",
    "nr_subcategory = df['subcategory'].nunique()\n",
    "active_projects = df['project_status'].value_counts()\n",
    "\n",
    "print(f'There are {nr_category} categories')\n",
    "print(f'There are {nr_subcategory} subcategories')\n",
    "print(f'There are {active_projects[1]} current projects and {active_projects[0]} past ones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb56264e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_category = pd.DataFrame({ 'Nr of subcategories': df.groupby('category')['subcategory'].nunique(),\n",
    "                            'Projects per category': df.groupby('category')['project_id'].nunique()\n",
    "                           }).sort_values('Projects per category', ascending = False)\n",
    "df_category[\"Frequency\"] = df_category['Projects per category']/df_category['Projects per category'].sum()*100\n",
    "\n",
    "df_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7d06b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_sub = df.groupby(['category','subcategory']).size()\n",
    "cat_sub_frame = cat_sub.to_frame()\n",
    "cat_sub_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f0f843-1ae9-47c6-a436-ca003aef9680",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb56179-5aca-4df4-86c6-db8efa9a2740",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df_grouped = df.groupby('category')\n",
    "df_grouped.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a7b5e9-ab7d-4ca3-8e43-e60de89a5caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e9d6e2-a1b9-4b18-83e0-0174a8aadac1",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "### Data Preparation\n",
    "Some features were initially retained for Exploratory Data analysis and Visualization purposes, but were then dropped in order to use machine learning models. These included features that are related to outcomes (e.g. the amount pledged, number of backers, spotlight) rather than to the properties of the project itself at the time of creation (e.g. category, goal, length of campaign). Other variables related to currencies and exchange rate for example will be dropped since not relevant to explain the outcome of a project. More explanations can be found below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2b472a-1e5f-4166-af42-73bff5ff1bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Eugenia about keeping just the variables useful for the Exp Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ac4128-364c-4d38-86d3-eb9624a5f0fc",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcc8979-d939-48e5-af3e-c0345b3c421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "df['launched_at'] = pd.to_datetime(df['launched_at'])\n",
    "df.set_index('launched_at').category.resample('M').count().plot() #resampling time series to Months\n",
    "plt.xlim('2009-01-01', '2018-12-31')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Number of projects')\n",
    "plt.title('Number of projects launched on Kickstarter, 2009-2019')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafde88b-9f1d-4c56-bd05-a0b2976d553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_df = df.set_index('launched_at').state\n",
    "year_df = pd.get_dummies(year_df).resample('YS').sum()\n",
    "year_df1 = year_df[['successful', 'failed']]\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(16,6))\n",
    "year_df1.plot.bar(ax=ax[0], color=['darkblue', 'grey'])\n",
    "ax[0].set_title('Total number of failed and successful projects')\n",
    "ax[0].set_xlabel('')\n",
    "\n",
    "year_df1[\"successful\"].div(year_df.sum(axis=1), axis=0).plot(kind='bar', ax=ax[1], color='darkblue') # Normalizes counts across rows\n",
    "ax[1].set_title('Success Rate')\n",
    "ax[1].set_xlabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b21a8a-8870-496e-9edf-4eecba9ec3cf",
   "metadata": {},
   "source": [
    "The left image depicts the total number of failed and successful projects, which indicated that the total number of failures and successes have been decreading since 2013. Not equally as the right images showcases: the success rate has depreciated over the past years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd3008e-a160-4246-890c-cdeeb8d5a6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2, ax3)) = plt.subplots(3, 1, figsize=(16,20))\n",
    "color = cm.CMRmap(np.linspace(0, 1, 16,df.category.nunique()))\n",
    "\n",
    "df.groupby('category').category.count().plot(kind='bar', ax=ax1, color=color)\n",
    "ax1.set_title('Number of projects')\n",
    "ax1.set_xlabel('')\n",
    "\n",
    "df.groupby('category').usd_goal.median().plot(kind='bar', ax=ax2, color=color)\n",
    "ax2.set_title('Median project goal ($)')\n",
    "ax2.set_xlabel('')\n",
    "\n",
    "df.groupby('category').usd_pledged.median().plot(kind='bar', ax=ax3, color=color)\n",
    "ax3.set_title('Median pledged per project ($)')\n",
    "ax3.set_xlabel('')\n",
    "\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b6ca1f-2b8c-497d-87e2-bf1659a623a6",
   "metadata": {},
   "source": [
    "The illustrations above aim to highlight the differences among the 15 different categories. Film&Video is the most used category, closely followed by music. Art, publishing and technology take the third place. However, technology has the highest median project goal. Design is the category with the highed pledged amount per project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37415bcb-ee63-4a22-81be-ba969c21dc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "df.set_index('launched_at').sort_index().usd_pledged.cumsum().plot()\n",
    "plt.xlim('2009-01-01', '2019-02-28') # Limiting to whole months\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Cumulative amount pledged in $', fontsize=12)\n",
    "plt.title('Cumulative pledged', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605f984a-f0a0-46b5-9062-1de4049bb680",
   "metadata": {},
   "source": [
    "The cumulative pledged figure shows the total of pledged amounts for each year 2009-2019. The trend can be split into two phases, with a change in 2013/2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897472ce-6b3b-438e-9ca3-fe5b7ebc793f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "sns.boxplot(df.launched_at.dt.year, np.log(df.usd_pledged))\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Amount pledged (log-transformed)',) #Log-transforming to make the trend clearer, as the distribution is heavily positively skewed\n",
    "plt.title('Amount pledged on Kickstarter projects, 2009-2019')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7861ea-b3d3-4821-942e-6b1af68134c5",
   "metadata": {},
   "source": [
    "Again, the trend can be split into two phases, with a change in 2014. We can see a greater variation in amounts pledged from 2014, with lower median amounts than before 2014, but generally higher mean amounts due to some very large projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc79fae-9ba7-476f-8233-7d03156f6ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequencies of word length\n",
    "freq_name = df['name_len'].value_counts(normalize=True).mul(100)\n",
    "freq_slug = df['slug_len'].value_counts(normalize=True).mul(100)\n",
    "freq_blurb = df['blurb_len'].value_counts(normalize=True).mul(100)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20,5))\n",
    "freq_blurb.plot(ax = axes[0], kind='bar', title = 'Frequency of Blurb length')\n",
    "freq_name.plot(ax = axes[1], kind='bar', title = 'Frequency of Name length')\n",
    "freq_slug.plot(ax = axes[2], kind='bar', title = 'Frequency of Slug length')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7dac06-90d4-4a85-9a4b-e24d79c25615",
   "metadata": {},
   "source": [
    "#### NLP - Analysis and visualization of text variables\n",
    "In the analysis below we will analyze the text variables (name, blurb, slug). \n",
    "\n",
    "**PREPROCESSING**: First of all we will preprocess text variables and clean them following these steps:\n",
    "- Lowercase \n",
    "- Remove extra whitespaces, punctuation special characters and numbers. Here, we assume that non-character words and numbers play a minimal role in prediction. \n",
    "- Expansion of the short form definitions\n",
    "- Lemmatization of the words, to get them into their root words\n",
    "- Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1019f7-cbe3-4d8f-9299-5371a1e0d629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contraction/Expansion of short words\n",
    "contractions_dict = {\n",
    "    'didn\\'t': 'did not',\n",
    "    'don\\'t': 'do not',\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"cant\": \"cannot\",\n",
    "    \"can't've\": \"cannot have\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"didnt\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"doesnt\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"dont\" : \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he had\",\n",
    "    \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'd'y\": \"how do you\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"i'd\": \"i had\",\n",
    "    \"i'd've\": \"i would have\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"im\": \"i am\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"needn't've\": \"need not have\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"sha'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\",\n",
    "    \"she'd\": \"she had\",\n",
    "    \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they had\",\n",
    "    \"they'd've\": \"they would have\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"to've\": \"to have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we had\",\n",
    "    \"we'd've\": \"we would have\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we'll've\": \"we will have\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"when've\": \"when have\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"where've\": \"where have\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"will've\": \"will have\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"won't've\": \"will not have\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"wouldn't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\"\n",
    "    }\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "contractions_re = re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "\n",
    "def expand_contractions(s, contractions_dict=contractions_dict):\n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, s)\n",
    "\n",
    "# Normalize words\n",
    "def normalize_document(d):\n",
    "    d = str(d).lower() # lower case\n",
    "    d = expand_contractions(d) #apply contraction-expansion function\n",
    "    d = re.sub(r'[^a-zA-Z\\s]', '', d, re.I|re.A) # substitute any character that is not a-z or A-Z and remove whitespaces\n",
    "    d = d.strip()\n",
    "    tokens = nltk.word_tokenize(d) # tokenize document\n",
    "    words =[lemmatizer.lemmatize(word) for word in tokens if word not in set(stopwords.words('english'))] # lemmatization\n",
    "    d = ' '.join(words) \n",
    "    return d\n",
    "\n",
    "df_nlp['blurb_clean'] = df_nlp['blurb'].apply(normalize_document)\n",
    "df_nlp['name_clean'] = df_nlp['name'].apply(normalize_document)\n",
    "df_nlp['slug_clean'] = df_nlp['slug'].str.replace(\"-\", \" \").apply(normalize_document) \n",
    "\n",
    "# Combine text variables\n",
    "df_nlp['combined_text'] = df_nlp['blurb_clean'] + df_nlp['slug_clean'] + df_nlp['name_clean']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffd0835-0897-4746-8203-6e405ee0ea2c",
   "metadata": {},
   "source": [
    "### Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5783d44f-7c08-46a6-9555-92af77924367",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(max_features=10000)\n",
    "X = vect.fit_transform(df_nlp['combined_text'].values)\n",
    "\n",
    "word_cnts = np.asarray(X.sum(axis=0)).ravel().tolist()  # for each word in column, sum all row counts\n",
    "feature_names = vect.get_feature_names()\n",
    "word_counts = pd.DataFrame({'word': feature_names, 'count': word_cnts})\n",
    "word_freq = pd.Series(word_counts['count'])\n",
    "word_freq.index = word_counts ['word']\n",
    "text_freq = word_freq.to_dict()\n",
    "word_counts.sort_values('count', ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a578da1e-6776-4b91-bede-9452eb72f6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width=800, height=800, max_font_size=200, background_color=\"white\").generate_from_frequencies(text_freq)\n",
    "                    \n",
    "plt.figure(figsize = (6, 6), facecolor = None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    "  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff37908-a118-4050-961a-7ca1688be3a1",
   "metadata": {},
   "source": [
    "### Topic Modeling and Document Clustering\n",
    "https://towardsdatascience.com/exploring-textual-data-using-lda-ef1f53c772a4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0916bac-fd3b-47f6-89f2-e4ae5615c5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=10, learning_method=\"batch\",\n",
    "                                max_iter=25, random_state=0)\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.sklearn.prepare(lda, X, vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d57547c-6657-44b7-b18e-5a9dfb068083",
   "metadata": {},
   "source": [
    "### Preprocessing and Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1f7b5e-75dc-4526-802f-bf17a6c06781",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Cleaned_Kickstarter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb02870a-ef5b-4626-8674-06216f6eff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform dataset\n",
    "df_transformed = df.drop(['project_id','nr_backers', 'name', 'slug', 'blurb', 'url', 'is_starrable', \n",
    "                            'usd_pledged', 'pledge_per_backer','creator_id', 'pledged','spotlight',\n",
    "                          'creator_name','city','subcategory_id', 'created_at', 'launched_at', 'deadline', 'currency', \n",
    "                          'current_currency','fx_rate', 'project_status','state_changed_at','disable_communication', \n",
    "                          'is_creator_registered','is_starrable','nation'], axis=1)\n",
    "\n",
    "df_transformed=df_transformed.loc[df['state'].isin([\"failed\",\"successful\"])]\n",
    "df_transformed=df_transformed.loc[df['project_status'].isin([\"inactive\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266dd45f-90e4-44dd-a6b0-182a3417948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7209db81-57d3-4b5b-acbd-22b2ce8d0c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed['staff_pick'] = df_transformed['staff_pick'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc06abc-e28d-49c0-bb7e-9097fd54fc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform y to 0:1 \n",
    "df_transformed[\"state\"]=df_transformed[\"state\"].replace({'failed' : 0, 'successful': 1})\n",
    "df_transformed = pd.get_dummies(df_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264b8b4d-0a45-46ba-bc5c-3d1550641e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unscaled = df_transformed.drop('state', axis=1)\n",
    "y = df_transformed.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4088cae1-2672-4557-8a11-b7e2d1c2177e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X_unscaled), columns=list(X_unscaled.columns))\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0734b810-e818-4ed1-a5e3-50e332b42684",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,shuffle=True, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04697a8e-e96e-4768-bb82-8e04ee23755d",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "## Overview\n",
    "\n",
    "2. LOGISTIC REGRESSION multiclass classification: Level based on pledged amount. Which variables are more correlated with price? A, B, C, D, E based on pledged amount - funding goal\n",
    "3. LOGISTIC REGRESSION WITH PCA (Domi): As the dataset hast a lot of features, we can usa PCA and reduce it to fewer features which still explain the variation --> model fitting / accuracy can be improved herewith confusion matrix and classification for using the best parameters\n",
    "4. RANDOM FOREST (Maria and Eugenia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114facb3-4825-4530-beef-f1b931a24a74",
   "metadata": {},
   "source": [
    "### **LOGISTIC REGRESSION**\n",
    "Logistic regression as a binary classifier in order to predict which of two categories a data point falls in to. Probability it will successful or not\n",
    "#### NLP - Logistig regression with text variable and outcome, using Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dabb845-4e3d-4382-a0ff-8c9dcb109900",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = ['canceled', 'suspended']\n",
    "\n",
    "df_nlp = df_nlp[df_nlp.state.isin(values) == False]\n",
    "\n",
    "X = df_nlp['combined_text'].values\n",
    "y = df_nlp[\"state\"].replace({'failed' : 0, 'successful': 1})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,shuffle=True, random_state=123)\n",
    "\n",
    "\n",
    "cv = CountVectorizer()\n",
    "cv_train_features = cv.fit_transform(X_train)\n",
    "\n",
    "cv_test_features = cv.transform(X_test)\n",
    "\n",
    "print('Bag of Words model:> Train features shape:', cv_train_features.shape, ' Test features shape:', cv_test_features.shape)\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', max_iter=500, C=1, solver='lbfgs', random_state=42)\n",
    "lr.fit(cv_train_features, y_train)\n",
    "\n",
    "\n",
    "lr_bow_predictions = lr.predict(cv_test_features)\n",
    "\n",
    "print(classification_report(y_test, lr_bow_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c64d48-24dd-496d-97d7-c891599d8034",
   "metadata": {},
   "source": [
    "#### NLP - Logistic regression with text variable and outcome, using Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f838189-ce60-4b7b-a18f-23ecad17f635",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = TfidfVectorizer(use_idf=True, min_df=5, max_df=1.0, ngram_range=(1,2),\n",
    "                     sublinear_tf=True)\n",
    "tv_train_features = tv.fit_transform(X_train)\n",
    "\n",
    "\n",
    "tv_test_features = tv.transform(X_test)\n",
    "\n",
    "print('TFIDF model:> Train features shape:', tv_train_features.shape, ' Test features shape:', tv_test_features.shape)\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', max_iter=500, C=1, solver='lbfgs', random_state=42)\n",
    "\n",
    "\n",
    "lr.fit(tv_train_features, y_train)\n",
    "\n",
    "\n",
    "lr_tfidf_predictions = lr.predict(tv_test_features)\n",
    "\n",
    "print(classification_report(y_test, lr_tfidf_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51501d3",
   "metadata": {},
   "source": [
    "#### Logistic Regression with all useful variables\n",
    "For our dummy model we train a classification model with several numeric and categorical features of completed projects to get an estimation whether the model would generally be able to predict the success of a project.\n",
    "\n",
    "Numeric features: \n",
    "- Nr of Backers\n",
    "- Goal\n",
    "\n",
    "Categorical features:\n",
    "- Category\n",
    "- Subcategory\n",
    "- Country \n",
    "- Nation\n",
    "- spotlight\n",
    "- staff_pick\n",
    "\n",
    "Target variable: \n",
    "- state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47196412",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import set_config \n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09f56d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Transform dataset\n",
    "df_dummy=df\n",
    "\n",
    "df_dummy=df_dummy.loc[df['state'].isin([\"failed\",\"successful\"])]\n",
    "df_dummy=df_dummy.loc[df['project_status'].isin([\"inactive\"])]\n",
    "\n",
    "#Drop unused columns\n",
    "del_col=['project_id', 'name', 'slug', 'blurb', 'url', 'subcategory_id', 'created_at', 'launched_at', 'deadline','pledged', 'currency', 'usd_pledged', 'current_currency',\n",
    "        'fx_rate', 'project_status','state_changed_at',\n",
    "        'disable_communication','is_starrable']\n",
    "\n",
    "df_dummy=df_dummy.drop(del_col, axis = 1)\n",
    "\n",
    "#Transform y to 0:1 \n",
    "y=df_dummy[\"state\"].replace({'failed' : 0, 'successful': 1})\n",
    "\n",
    "X=df_dummy\n",
    "X=X.drop('state', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a96d827-78bd-4f05-9a97-aeb5a7db8462",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bc9415",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Trial #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65b5620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build preprocessor for columns\n",
    "#Standardize numerical features\n",
    "numeric_features=[\"nr_backers\", \"usd_goal\"]\n",
    "numeric_transformer = Pipeline(steps =[\n",
    "    (\"imputer\",SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())])\n",
    "\n",
    "#Encode categorical features\n",
    "cat_features=[\"category\", \"subcategory\", \"country\", \"nation\", \"spotlight\", \"staff_pick\"]\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "#Column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, cat_features)])\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "#Run Column Transformer\n",
    "X_trans = preprocessor.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_trans,y,test_size=0.2,shuffle=True, random_state=123)\n",
    "\n",
    "#Build Logistic Regression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344fa396-379f-4acc-b9e4-3df48493e288",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build preprocessor for columns\n",
    "#Standardize numerical features\n",
    "numeric_features=[ \"usd_goal\"]\n",
    "numeric_transformer = Pipeline(steps =[\n",
    "    (\"imputer\",SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())])\n",
    "\n",
    "#Encode categorical features\n",
    "cat_features=[\"category\", \"subcategory\", \"country\", \"nation\", \"staff_pick\"]\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "#Column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, cat_features)])\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "#Run Column Transformer\n",
    "X_trans = preprocessor.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_trans,y,test_size=0.2,shuffle=True, random_state=123)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf4ac25",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Evaluation #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14f54a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression scores\n",
    "print(\"Logistic regression score for training set:\", round(clf.score(X_train, y_train),5))\n",
    "print(\"Logistic regression score for test set:\", round(clf.score(X_test, y_test),5))\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f3bffb",
   "metadata": {},
   "source": [
    "The performance metrics are  extremely high and decribe a perfect model. This is mainly because  the feature \"spotlight\" is perfectly correlated to the target variable. In the following trial we will evaluate the model without this feature. Nonetheless, \"spotlight\" is an important variable that needs further analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1de38f2",
   "metadata": {},
   "source": [
    "#### Trial #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2ce295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build preprocessor for columns\n",
    "#Standardize numerical features\n",
    "numeric_features=[\"nr_backers\", \"usd_goal\"]\n",
    "numeric_transformer = Pipeline(steps =[\n",
    "    (\"imputer\",SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())])\n",
    "\n",
    "#Encode categorical features\n",
    "cat_features=[\"category\", \"subcategory\", \"nation\", \"staff_pick\"]\n",
    "categorical_transformer = OneHotEncoder(sparse = False, handle_unknown=\"ignore\")\n",
    "\n",
    "#Column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, cat_features)])\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "#Run Column Transformer\n",
    "X_trans = preprocessor.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_trans,y,test_size=0.2,shuffle=True, random_state=123)\n",
    "\n",
    "#Build Logistic Regression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccaea08",
   "metadata": {},
   "source": [
    "#### Evaluation #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a8c523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression scores\n",
    "print(\"Logistic regression score for training set:\", round(clf.score(X_train, y_train),5))\n",
    "print(\"Logistic regression score for test set:\", round(clf.score(X_test, y_test),5))\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107c4e02-5307-4781-916c-c3765def7015",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6fb774-4ce4-4d47-8f23-b19843f7e24c",
   "metadata": {},
   "source": [
    "**Feature Selection with Variance Threshold**\n",
    "\n",
    "In this part we're optimizing our model through feature selection with a variance threshold. Thus, we're testing the model for \n",
    "multiple thresholds to decide which threshold provides us with the highest weighted F1 score. Since our data set is balanced and we're aiming for a good overall classification of samples we're relying on the weighted F1-score to correctly represent the proportion of each class’s support relative to the sum of all support values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d626f7b7-624c-41e5-a566-a59323e20e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_variance_threshold(X, preprocessor, varthresh):\n",
    "    X_trans = preprocessor.fit_transform(X)\n",
    "\n",
    "    #Variance Threshold\n",
    "    sel = VarianceThreshold(threshold = (varthresh*(1-varthresh)))\n",
    "    X_trans_sel=pd.DataFrame(X_trans)\n",
    "    X_trans_sel=sel.fit_transform(X_trans_sel)\n",
    "\n",
    "    #Train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_trans_sel,y,test_size=0.2,shuffle=True, random_state=123)\n",
    "\n",
    "    #Build Logistic Regression\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Making predictions\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "\n",
    "    # Logistic regression scores\n",
    "    scores={\"Variance Threshold\": varthresh, \"Train Score\":round(clf.score(X_train, y_train),8), \n",
    "            \"Test Score\":round(clf.score(X_test, y_test),8), \n",
    "            \"F1-Score Train\":round(f1_score(y_train, y_train_pred, average='weighted'),8),\n",
    "            \"F1 Score Test\":round(f1_score(y_test, y_test_pred, average='weighted'),8)}\n",
    "    scores=pd.DataFrame(data=scores, index=[varthresh])\n",
    "    return scores\n",
    "\n",
    "scoring= pd.DataFrame(columns = [\"Variance Threshold\", \"Train Score\", \"Test Score\"])\n",
    "\n",
    "#Iterate thresholds\n",
    "for j in np.arange(0.8,1,0.01):\n",
    "    xx=opt_variance_threshold(X, preprocessor, j)\n",
    "    scoring=pd.concat([scoring,xx], axis=0)\n",
    "\n",
    "#Select optimal threshold\n",
    "opt_thresh=scoring['F1 Score Test'].idxmax().round(2)\n",
    "print(\"Optimal threshold for max f1-score test set: \"+str(opt_thresh))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f66dcf-799d-468d-90e2-47d74f3ec0dd",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning Logistic Regression using GridSearch\n",
    "In this part we're tuning the hyperparameter using cross-validated GridSearch with our optimized Variance Threshold#Te. We're optimizing the C-Value as the main hyperparameter of the regression, the penalty of the loss function, as well as the solver itself. The results will be tested against the F1 score, as in the previous feature selection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c0c300-aba1-4968-be9e-7434c5dc9ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(X, preprocessor, vt_opt):\n",
    "    X_trans = preprocessor.fit_transform(X)\n",
    "\n",
    "    #Variance Threshold\n",
    "    sel = VarianceThreshold(threshold = (vt_opt*(1-vt_opt)))\n",
    "    X_trans_sel=pd.DataFrame(X_trans)\n",
    "    X_trans_sel=sel.fit_transform(X_trans_sel)\n",
    "\n",
    "    #Train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_trans_sel,y,test_size=0.2,shuffle=True, random_state=123)\n",
    "\n",
    "    grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"], \"solver\": ['newton-cg', 'lbfgs', 'liblinear']}\n",
    "    \n",
    "    logreg=LogisticRegression()\n",
    "    logreg_cv=GridSearchCV(logreg,grid,cv=3, scoring =\"f1\")\n",
    "    logreg_cv.fit(X_train,y_train)\n",
    "\n",
    "    print(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "    \n",
    "    return logreg_cv.best_params_\n",
    "\n",
    "check=grid_search(X, preprocessor, opt_thresh)\n",
    "\n",
    "opt_hyper=int(check[\"C\"])\n",
    "opt_regularization=str(check[\"penalty\"])\n",
    "opt_solver=str(check[\"solver\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc5d609-0d11-40a5-873e-f0136f4d3825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing:\n",
    "def test_model(X, preprocessor, vt_opt, opt_hyper, opt_regularization, opt_solver):\n",
    "    X_trans = preprocessor.fit_transform(X)\n",
    "\n",
    "    #Optimal Variance Threshold\n",
    "    sel = VarianceThreshold(threshold = (vt_opt*(1-vt_opt)))\n",
    "    X_trans_sel=pd.DataFrame(X_trans)\n",
    "    X_trans_sel=sel.fit_transform(X_trans_sel)\n",
    "\n",
    "    #Train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_trans_sel,y,test_size=0.2,shuffle=True, random_state=123)\n",
    "    \n",
    "    #LogReg with optimal parameters\n",
    "    clf=LogisticRegressionCV(cv=5, Cs=opt_hyper, solver=opt_solver, penalty=opt_regularization)\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    # Making predictions\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    \n",
    "    #Scoring\n",
    "    print(\"F1-Score Train\"+ str(round(f1_score(y_train, y_train_pred, average='weighted'),8)))\n",
    "    print(\"F1 Score Test\"+str(round(f1_score(y_test, y_test_pred, average='weighted'),8)))\n",
    "    \n",
    "    return #F1 Score\n",
    "    \n",
    "opt_hyper=int(check[\"C\"])\n",
    "test_model(X,preprocessor, opt_thresh, opt_hyper, opt_regularization, opt_solver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78be9bbc-6db0-4d79-af0e-34663f63bf55",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Interpretation:\n",
    "xxx\n",
    "\n",
    "xxx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afeec316-444b-4511-9cb5-8c4599a874c3",
   "metadata": {},
   "source": [
    "**To Do's**\n",
    "- Feature selection: Welche features sollten ins Modell mitaufgenommen werden und welche nicht? --> **FEATURE ENGINEERING AND FEATURE SELECTION**\n",
    "\n",
    "**Feature Engineering**\n",
    "Cat features:\n",
    "--> Ordinal Encoder vs One-Hot Encoder?\n",
    "--> Sparse representation when many unique categorical features\n",
    "\n",
    "Numeric features:\n",
    "- Counting \n",
    "- Rounding\n",
    "- Binning / Discretization (Könnte gut sein)\n",
    "- Statistical transformations: LogTransformation; Box-Cox Transformation (Könnte gut sein)\n",
    "- Scaling: Bring all values to a scale from 0 to 1 \n",
    "- Normalization: All samples have a unit form\n",
    "\n",
    "Feature cross: \n",
    "A feature cross is a synthetic feature that encodes nonlinearity in the feature space by multiplying two or more input features\n",
    "\n",
    "Engineering: \n",
    "created_at: when the project has been created - yyyy/mm/dd.\n",
    "launched_at: launch date of the project - yyyy/mm/dd.\n",
    "deadline: deadline of the project - yyyy/mm/dd.\n",
    "\n",
    "- Campaign length — number of days from launch to deadline: DEADLINE - LAUNCH DATE\n",
    "- Number of days from page creation to project launch: LAUNCH DATE - CREATION DATE\n",
    "- Name: Word length\n",
    "- Blurb: Word length\n",
    "\n",
    "Opt: \n",
    "- Month of launch\n",
    "- Month of deadline\n",
    "- Day of launch\n",
    "- Day of deadline\n",
    "- Two hour window of launch\n",
    "- Two hour window of deadline\n",
    "\n",
    "**Feature Selection**\n",
    "Avoid rarely used discrete feature values\n",
    "1. Variance Threshold -> Opt Threshold bei 0.96\n",
    "2. Recursive Feature Elimination\n",
    "3. SelectFromModel\n",
    "\n",
    "Coefficients abgleichen für jedes Feature\n",
    "\n",
    "Features:\n",
    "Numeric:\n",
    "    Goal: Sinnvoll\n",
    "    Number of backers: Sinvoll\n",
    "    \n",
    "Cat:\n",
    "    Category:\n",
    "    Subcategory:\n",
    "    Country: \n",
    "    Nation: Macht keinen sinn\n",
    "    Staff pick: Sinnvoll \n",
    "\n",
    "- Confusion Matrix\n",
    "- ROC und AUC curves für bessere Beurteilung (LogLoss??)\n",
    "- Kann F1 Score als zentrale Metrik genommen werden? (Es ist nicht eindeutig ob True False oder False True schlimmer ist)\n",
    "- 205k Samples insgesamt --> SGD classifier for large datasets >100K samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffb28ec-488b-4ef4-aa2f-0faf2842c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f95fd5-c49a-446e-821e-579229f58195",
   "metadata": {},
   "source": [
    "### 4. Logistic Regression with PCA\n",
    "The dependent (y) and independent (X) features will be separated into separate datasets. Because the features are on different scales, independent features will be transformed and normalised using StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1cda96-6906-45b7-87b1-3ee5a112e540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_recall_fscore_support\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1226f91-7ce9-44ed-a6b7-ffafcc0d99e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting a logistic regression model with default parameters\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X_train,y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_hat_train = logistic_regression.predict(X_train)\n",
    "y_hat_test = logistic_regression.predict(X_test)\n",
    "# Logistic regression scores\n",
    "print(\"Log Reg score, training set:\", round(logistic_regression.score(X_train, y_train),5))\n",
    "print(\"Log Reg score, test set:\", round(logistic_regression.score(X_test, y_test),5))\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb73b6f-d88f-42ec-944d-410c922cacc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cf(y_true, y_pred, class_names=None, model_name=None):\n",
    "    cf = confusion_matrix(y_true, y_pred)\n",
    "    plt.imshow(cf, cmap=plt.cm.Blues)\n",
    "    plt.grid(b=None)\n",
    "    if model_name:\n",
    "        plt.title(\"Confusion Matrix: {}\".format(model_name))\n",
    "    else:\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    \n",
    "    class_names = set(y_true)\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    if class_names:\n",
    "        plt.xticks(tick_marks, class_names)\n",
    "        plt.yticks(tick_marks, class_names)\n",
    "    \n",
    "    thresh = cf.max() / 2.\n",
    "    \n",
    "    for i, j in itertools.product(range(cf.shape[0]), range(cf.shape[1])):\n",
    "        plt.text(j, i, cf[i, j], horizontalalignment='center', color='white' if cf[i, j] > thresh else 'black')\n",
    "\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6124bb47-8952-4346-a651-5bcec8402382",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cf(y_test, y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb150f48-5114-4880-bc12-7b0c9873c83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the AUC-ROC\n",
    "y_score = logreg.fit(X_train, y_train).decision_function(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "\n",
    "print('AUC:', round(auc(fpr, tpr),5))\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.yticks([i/20.0 for i in range(21)])\n",
    "plt.xticks([i/20.0 for i in range(21)])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f756e8-a773-4f67-ba2d-2d5cf7670b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = df.drop([\"pledge_per_backer\",\"name\",\"slug\",\"blurb\",\"nation\",\"city\",\"creator_id\",\"creator_name\",\"is_creator_registered\",\"url\",\"subcategory_id\",'nr_backers', 'created_at', 'deadline', 'is_starrable', 'launched_at', 'usd_pledged', 'subcategory', \"pledged\",\"currency\",\"current_currency\",\"fx_rate\", \"project_status\", \"state_changed_at\", \"disable_communication\",\"spotlight\"], axis=1)\n",
    "df_transformed = df_transformed.set_index('project_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4173e97-2aac-47aa-92b4-6c7b5edf838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed['state'] = df_transformed['state'].replace({'failed': 0, 'successful': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ecdc54-311a-4dba-a843-3f9f809a33ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed['staff_pick'] = df_transformed['staff_pick'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b4caf7-20ce-4e71-b564-b38ef4d44ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d89c53-fe54-4d98-aee5-245e41614276",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = pd.get_dummies(df_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edecc65b-07db-4880-a650-f774ee4159f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unscaled = df_transformed.drop(['state_0','state_1'],axis=1)\n",
    "y = df_transformed.state_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce34da0-20c1-442c-9b6a-7c093665a836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the data\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X_unscaled), columns=list(X_unscaled.columns))\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380af140-771a-4549-ab93-0cc9586d9cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting\n",
    "pca = PCA()\n",
    "pca.fit_transform(X)\n",
    "explained_var = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "# Plotting the amount of variation explained by PCA with different numbers of components\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(list(range(1, len(explained_var)+1)), explained_var)\n",
    "plt.title('Amount of variation explained by PCA', fontsize=14)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Explained variance');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d33cf3-c8dd-48cb-b871-814d289e6724",
   "metadata": {},
   "source": [
    "The figure aboves explains that the highest number of components is 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9251a2e1-f662-4828-a2af-575fe2ed1d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"80% of variance explained with\", np.where(explained_var > 0.8)[0][0], \"components\")\n",
    "print(\"90% of variance explained with\", np.where(explained_var > 0.9)[0][0], \"components\")\n",
    "print(\"80% of variance explained with\", np.where(explained_var > 0.99)[0][0], \"components\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f11b69-e38e-4633-846e-d1373fe7ac4e",
   "metadata": {},
   "source": [
    "The results indiciate that the score is highest for 72 components, however the difference is small >1% improvement from 50 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73be4a5f-0a5f-4f03-8922-56c172744436",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comps = [50,59,72]\n",
    "for n in n_comps:\n",
    "    pipe = Pipeline([('pca', PCA(n_components=n)), ('clf', LogisticRegression())])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    print(\"\\nNumber of components:\", n)\n",
    "    print(\"Score:\", round(pipe.score(X_test, y_test),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fd86c7-af93-4250-a45a-9a68960c0c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=72)\n",
    "pca.fit_transform(X)\n",
    "\n",
    "# Set components as columns and features as rows\n",
    "pca_72_components = pd.DataFrame(pca.components_,columns=X.columns).T\n",
    "pca_72_components['mean_weight'] = pca_72_components.iloc[:].abs().mean(axis=1)\n",
    "pca_72_components.sort_values('mean_weight', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a7e319-a233-4d40-81de-c20b32719490",
   "metadata": {},
   "source": [
    "Below you can see the average weight of each feature on each component. We can see that the average weight of how much each feature is included in each component is pretty similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f43c6e4-3bc1-492b-9646-fb09b9f8e0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting feature importances\n",
    "plt.figure(figsize=(20,5))\n",
    "pca_72_components.mean_weight.sort_values(ascending=False).plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520ef607-88ab-4869-9d3e-9608f6649642",
   "metadata": {},
   "source": [
    "These are the top 5 most important features in the top three most important components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceae49a4-ae12-48f0-8598-6b7f183c8a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_72_components[0].map(lambda x : x).abs().sort_values(ascending = False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deee2a91-ad08-43bb-9ce8-b5674de19428",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_72_components[1].map(lambda x : x).abs().sort_values(ascending = False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466d157c-3d84-47f0-958e-75d51b3791d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_72_components[2].map(lambda x : x).abs().sort_values(ascending = False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d6b0d2-4e04-4d0c-8382-12958595c93c",
   "metadata": {},
   "source": [
    "### 5. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c50cd74-95f3-49fd-9cdc-c98526b80b44",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> conda install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0846253-62bb-4a54-8475-7eb095dd9fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import set_config\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcffbd8-51d0-475d-83e0-310ad716b2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_cf(y_true, y_pred, class_names=None, model_name=None):\n",
    "    \"\"\"Plots a confusion matrix\"\"\"\n",
    "    cf = confusion_matrix(y_true, y_pred)\n",
    "    plt.imshow(cf, cmap=plt.cm.Greens)\n",
    "    plt.grid(b=None)\n",
    "    if model_name:\n",
    "        plt.title(\"Confusion Matrix: {}\".format(model_name))\n",
    "    else:\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    \n",
    "    class_names = set(y_true)\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    if class_names:\n",
    "        plt.xticks(tick_marks, class_names)\n",
    "        plt.yticks(tick_marks, class_names)\n",
    "    \n",
    "    thresh = cf.max() / 2.\n",
    "    \n",
    "    for i, j in itertools.product(range(cf.shape[0]), range(cf.shape[1])):\n",
    "        plt.text(j, i, cf[i, j], horizontalalignment='center', color='white' if cf[i, j] > thresh else 'black')\n",
    "\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d1b640-9be5-4cef-b4eb-4c46a10b3c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, auc, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "y_pred = rnd_clf.predict(X_test)\n",
    "\n",
    "print(\"\\nAccuracy score:\")\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "plot_cf(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0946f9c8-a762-4fd4-9648-a274881a5db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp=[]\n",
    "for name, score in zip(X, rnd_clf.feature_importances_):\n",
    "    feat_imp.append((name, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb1792e-1f02-4552-9424-19147b6d13c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_imp = pd.DataFrame(feat_imp, columns=['Features','Importance'])\n",
    "top_feat_imp = df_feat_imp.sort_values(by=['Importance'], ascending=False).head(20)\n",
    "top_feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a6462a-23d0-4ccf-af39-e60f09345129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.barplot(x=top_feat_imp.Importance, y=top_feat_imp.Features)\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b8c28e-054c-4060-9956-6005ec436022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New random forest with only the two most important variables\n",
    "rf_most_important = RandomForestClassifier(n_estimators= 100, random_state=42)\n",
    "\n",
    "X_train_imp = X_train[['usd_goal','creation_to_launch_days','blurb_len','name_len','campaign_days','staff_pick_True', 'staff_pick_False']]\n",
    "X_test_imp = X_test[['usd_goal','creation_to_launch_days','blurb_len','name_len','campaign_days','staff_pick_True', 'staff_pick_False']]\n",
    "\n",
    "\n",
    "rf_most_important.fit(X_train_imp, y_train)\n",
    "predictions = rf_most_important.predict(X_test_imp)\n",
    "\n",
    "print(\"\\nAccuracy score:\")\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "\n",
    "plot_cf(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2741bf0a-70b1-4f4e-972e-a3cb96860939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using GridSearchCV to test multiple different parameters\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf_start = time.time()\n",
    "\n",
    "rnd_clf = RandomForestClassifier()\n",
    "\n",
    "params_rf = {'n_estimators': [100, 200, 400],\n",
    "             'max_depth': [20, 30, 40],\n",
    "             'min_samples_split':[0.001, 0.01]}\n",
    "\n",
    "grid_rf = GridSearchCV(estimator = RandomForestClassifier(), param_grid = params_rf, cv=5)\n",
    "\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "rf_end = time.time()\n",
    "\n",
    "rf_best_score = grid_rf.best_score_\n",
    "rf_best_params = grid_rf.best_params_\n",
    "\n",
    "print(f\"Time taken to run: {round((rf_end - rf_start)/60,1)} minutes\")\n",
    "print(\"Best accuracy:\", round(rf_best_score,2))\n",
    "print(\"Best parameters:\", rf_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96501d43-588a-4eee-8e4b-9f1a1458c777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "train_scoreNum, test_scoreNum = validation_curve(\n",
    "                                RandomForestClassifier(),\n",
    "                                X = X_train, y = y_train, \n",
    "                                param_name = 'n_estimators', \n",
    "                                param_range = [100, 300, 500, 750, 800, 1200], cv = 3)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "833ac51a-600c-480c-881c-15e041b9e0c9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "# Too slow, I'll try to adjust it\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "rf_start2 = time.time()\n",
    "\n",
    "rf2 = RandomForestClassifier(min_samples_split=0.001, verbose=2)\n",
    "\n",
    "params_rf2 = [ \n",
    "  {'n_estimators': [200, 400],\n",
    "   'max_depth': [20, 35]\n",
    "  }\n",
    "]\n",
    "\n",
    "grid_rf2 = GridSearchCV(estimator=rf2, param_grid=params_rf2, cv=5)\n",
    "\n",
    "grid_rf2.fit(X_train, y_train)\n",
    "\n",
    "rf_end2 = time.time()\n",
    "\n",
    "rf_best_score2 = grid_rf2.best_score_\n",
    "rf_best_params2 = grid_rf2.best_params_\n",
    "\n",
    "print(f\"Time taken to run: {round((rf_end2 - rf_start2)/60,1)} minutes\")\n",
    "print(\"Best accuracy:\", round(rf_best_score2,2))\n",
    "print(\"Best parameters:\", rf_best_params2)\n",
    "\n",
    "#Best Random Forest\n",
    "\n",
    "best_rf = RandomForestClassifier(max_depth=35, min_samples_split=0.001, n_estimators=400)\n",
    "\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "rf_y_hat_train2 = best_rf.predict(X_train)\n",
    "rf_y_hat_test2 = best_rf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest score for training set:\", round(best_rf.score(X_train, y_train),5))\n",
    "print(\"Random Forest score for test set:\", round(best_rf.score(X_test, y_test),5))\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, rf_y_hat_test2))\n",
    "plot_cf(y_test, rf_y_hat_test2)\n",
    "\n",
    "#Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b727555b-367e-4a6c-b7a1-9cfb6fe1109b",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558e4d12-0d6b-4771-bf17-d33dc8c6e32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Score:\", round(xgb_clf.score(X_test, y_test),5))\n",
    "\n",
    "\n",
    "#pipeline_xgb = Pipeline([#pca\n",
    "                    #('clf', xgb.XGBClassifier())])\n",
    "#pipeline_xgb.fit(X_train, y_train)\n",
    "#print(\"Score:\", round(pipeline_xgb.score(X_test, y_test),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ae503e-8ff3-4c13-b98b-74068bc34d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier()\n",
    "\n",
    "params_xgb = [ \n",
    "  {'clf__n_estimators': [100],\n",
    "   'clf__max_depth': [25, 35],\n",
    "   'clf__learning_rate': [0.01, 0.1],\n",
    "   'clf__subsample': [0.7, 1],\n",
    "   'clf__min_child_weight': [20, 100]\n",
    "  }\n",
    "]\n",
    "\n",
    "grid_xgb = GridSearchCV(estimator=xgb_clf,\n",
    "                  param_grid=params_xgb,\n",
    "                  cv=5)\n",
    "\n",
    "grid_xgb.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "xgb_best_score = grid_xgb.best_score_\n",
    "xgb_best_params = grid_xgb.best_params_\n",
    "\n",
    "\n",
    "print(\"Best accuracy:\", round(xgb_best_score,2))\n",
    "print(\"Best parameters:\", xgb_best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7735718a-f9ed-40f6-b4fb-910fbaa32cf7",
   "metadata": {},
   "source": [
    "#### EVALUATION OF THE MODEL – criteria\n",
    "**TO BE REVIEWED**\n",
    "1. Proportion of the projects where the model accurately predicted the final success or failure of the project. \n",
    "2. The difference between the level of the pledged amount predicted by the model against the amount achieved \n",
    "3. The number of backers predicted for the specific type of project from the model versus the actual amount of backers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e882ca-9ae1-42ae-b010-6d3f97b4aa2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
